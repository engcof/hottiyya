# library_service.py
import os
import shutil
import tempfile
import asyncio
import socket
import httplib2
import json
import fitz  # PyMuPDF
import cloudinary.uploader
import requests
from fastapi import UploadFile
from google.oauth2.credentials import Credentials
from google.auth.transport.requests import Request
from googleapiclient.http import MediaFileUpload
from googleapiclient.discovery import build
from postgresql import get_db_context
from psycopg2.extras import RealDictCursor

class LibraryService:
    SCOPES = ['https://www.googleapis.com/auth/drive.file']
    TOKEN_FILE = 'token.json'
    GOOGLE_DRIVE_FOLDER_ID = '1nbegMhH8rIQf7mRiNHkv4P5wamwFMbeZ'

    @staticmethod
    def get_drive_service():
        """Ø¨Ù†Ø§Ø¡ Ø®Ø¯Ù…Ø© Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…ØªÙ‚Ø¯Ù…Ø© Ù„Ù‚Ø·Ø¹ Ø§Ù„Ø§ØªØµØ§Ù„ ÙˆDNS"""
        from googleapiclient.discovery import build
        from google.auth.transport.requests import Request
        from google.oauth2.credentials import Credentials
        import google_auth_httplib2
        import httplib2
        import socket

        # 1. Ø­Ù„ Ù…Ø´ÙƒÙ„Ø© Ø§Ù„Ù€ DNS ÙˆØ§Ù„Ø§ØªØµØ§Ù„ Ø¹Ù„Ù‰ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù†Ø¸Ø§Ù… Ù„Ù‡Ø°Ù‡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©
        socket.setdefaulttimeout(600) 
        
        creds = Credentials.from_authorized_user_file(LibraryService.TOKEN_FILE, LibraryService.SCOPES)
        
        if creds.expired and creds.refresh_token:
            creds.refresh(Request())
            with open(LibraryService.TOKEN_FILE, 'w') as token:
                token.write(creds.to_json())
        
        # 2. Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ø­ÙˆÙ„ HTTP Ù…Ø¹ Ø®Ø§ØµÙŠØ© Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø¹Ù†Ø¯ Ø­Ø¯ÙˆØ« Timeout
        # Ù†Ù‚ÙˆÙ… Ø¨Ø¶Ø¨Ø· disable_ssl_certificate_validation=False Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ø£Ù…Ø§Ù†
        http_transport = httplib2.Http(timeout=600)
        
        # 3. Ø§Ù„Ø±Ø¨Ø· Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙƒØªØ¨Ø© google_auth_httplib2
        authorized_http = google_auth_httplib2.AuthorizedHttp(creds, http=http_transport)
        
        # 4. Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø®Ø¯Ù…Ø© Ù…Ø¹ ØªÙ…ÙƒÙŠÙ† Ø¹Ø¯Ø¯ Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ø§ØªØµØ§Ù„ (Retries)
        return build('drive', 'v3', http=authorized_http, static_discovery=False)
    @staticmethod
    async def process_and_get_metadata(file: UploadFile):
        """
        Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ (Ø³Ø±ÙŠØ¹Ø©): 
        ØªØ¶ØºØ· Ø§Ù„Ù…Ù„Ù ÙˆØªØ³ØªØ®Ø±Ø¬ Ø§Ù„ØºÙ„Ø§Ù ÙˆØªØ±ÙØ¹ Ø§Ù„ØºÙ„Ø§Ù ÙÙ‚Ø·.
        ØªØ¹ÙŠØ¯ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø­Ù„ÙŠ Ù„Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¶ØºÙˆØ· Ù„ÙŠØªÙ… Ø±ÙØ¹Ù‡ ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ©.
        """
        temp_input = None
        try:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
                shutil.copyfileobj(file.file, tmp)
                temp_input = tmp.name

            temp_output = temp_input.replace(".pdf", "_compressed.pdf")
            
            # Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø¶ØºØ· Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ghostscript
            gs_command = ["gs", "-sDEVICE=pdfwrite", "-dCompatibilityLevel=1.4", "-dPDFSETTINGS=/ebook", 
                          "-dNOPAUSE", "-dQUIET", "-dBATCH", f"-sOutputFile={temp_output}", temp_input]
            process = await asyncio.create_subprocess_exec(*gs_command)
            await process.wait()

            final_local_path = temp_output if os.path.exists(temp_output) else temp_input
            file_size_mb = os.path.getsize(final_local_path) / (1024 * 1024)
            size_str = f"{file_size_mb:.2f} MB"

            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØºÙ„Ø§Ù ÙÙˆØ±Ø§Ù‹
            temp_cover = final_local_path.replace(".pdf", ".jpg")
            doc = fitz.open(final_local_path)
            pix = doc.load_page(0).get_pixmap(matrix=fitz.Matrix(1.5, 1.5))
            pix.save(temp_cover)
            doc.close()
            
            # Ø±ÙØ¹ Ø§Ù„ØºÙ„Ø§Ù Ù„Ù€ Cloudinary (Ø³Ø±ÙŠØ¹)
            cover_res = cloudinary.uploader.upload(temp_cover, folder="hottiyya_library/covers")
            
            if os.path.exists(temp_cover): os.remove(temp_cover)
            if temp_input != final_local_path and os.path.exists(temp_input): os.remove(temp_input)

            return final_local_path, cover_res.get("secure_url"), size_str
        except Exception as e:
            if temp_input and os.path.exists(temp_input): os.remove(temp_input)
            raise e

    @staticmethod
    def background_upload(file_path: str, filename: str, book_id: int):
        """
        Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ© (Ø®Ù„ÙÙŠØ©):
        ØªØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø±ÙØ¹ Ø§Ù„Ù…Ø³ØªØ£Ù†Ù Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø© ÙˆØªØ­Ø¯ÙŠØ« Ø§Ù„Ø­Ø§Ù„Ø© Ø¹Ù†Ø¯ Ø§Ù„ÙØ´Ù„.
        """
        try:
            file_size_mb = os.path.getsize(file_path) / (1024 * 1024)
            final_url = None

            if file_size_mb < 10:
                # Ø§Ù„Ø±ÙØ¹ Ù„Ù€ Cloudinary Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØµØºÙŠØ±Ø© (Ø³Ø±ÙŠØ¹ ÙˆÙ…Ø³ØªÙ‚Ø±)
                res = cloudinary.uploader.upload(file_path, resource_type="raw", folder="hottiyya_library/books")
                final_url = res['secure_url']
            else:
                # Ø§Ù„Ø±ÙØ¹ Ù„Ù€ Google Drive Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø© (Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡)
                service = LibraryService.get_drive_service()
                media = MediaFileUpload(
                    file_path, 
                    mimetype='application/pdf', 
                    resumable=True, # ØªÙØ¹ÙŠÙ„ Ø§Ø³ØªØ¦Ù†Ø§Ù Ø§Ù„Ø±ÙØ¹ Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø©
                    chunksize=1024*1024 # Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù ÙƒØ£Ø¬Ø²Ø§Ø¡ (1 Ù…ÙŠØ¬Ø§ Ù„ÙƒÙ„ Ø¬Ø²Ø¡) Ù„ØªÙ‚Ù„ÙŠÙ„ Ø­Ù…Ù„ Ø§Ù„Ø°Ø§ÙƒØ±Ø© ÙˆØ§Ù„Ù€ Timeout
                )
                
                # Ø¯Ø§Ø®Ù„ Ø¯Ø§Ù„Ø© background_upload ÙÙŠ LibraryService
                request = service.files().create(
                    body={'name': filename, 'parents': [LibraryService.GOOGLE_DRIVE_FOLDER_ID]},
                    media_body=media, fields='id'
                )
                
                response = None
                retries = 0
                max_retries = 5
                
                while response is None:
                    try:
                        status, response = request.next_chunk()
                        if status:
                            print(f"ğŸ”¼ ÙƒØªØ§Ø¨ {book_id}: ØªÙ… Ø±ÙØ¹ {int(status.progress() * 100)}%")
                    except (socket.timeout, httplib2.ServerNotFoundError, ConnectionError) as e:
                        retries += 1
                        if retries > max_retries:
                            raise e
                        print(f"âš ï¸ Ø§Ù†Ù‚Ø·Ø¹ Ø§Ù„Ø§ØªØµØ§Ù„... Ù…Ø­Ø§ÙˆÙ„Ø© Ø±Ù‚Ù… {retries} Ù„Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ø§ØªØµØ§Ù„.")
                        asyncio.sleep(5) # Ø§Ù†ØªØ¸Ø± Ù‚Ù„ÙŠÙ„Ø§Ù‹ Ù‚Ø¨Ù„ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©

            # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø±Ø§Ø¨Ø· ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¹Ù†Ø¯ Ø§Ù„Ù†Ø¬Ø§Ø­
            with get_db_context() as conn:
                with conn.cursor() as cur:
                    cur.execute("UPDATE library SET file_url = %s WHERE id = %s", (final_url, book_id))
                    conn.commit()
            
            print(f"âœ… ØªÙ… Ø§ÙƒØªÙ…Ø§Ù„ Ø±ÙØ¹ Ø§Ù„ÙƒØªØ§Ø¨ Ø±Ù‚Ù… {book_id} Ø¨Ù†Ø¬Ø§Ø­.")
            
        except Exception as e:
            # ÙÙŠ Ø­Ø§Ù„ Ø§Ù„ÙØ´Ù„: Ù†Ù‚ÙˆÙ… Ø¨ØªØºÙŠÙŠØ± Ø§Ù„Ø­Ø§Ù„Ø© ÙÙŠ Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø© Ù„ÙƒÙŠ Ù„Ø§ ØªØ¸Ù„ "pending"
            with get_db_context() as conn:
                with conn.cursor() as cur:
                    cur.execute("UPDATE library SET file_url = %s WHERE id = %s", ('error', book_id))
                    conn.commit()
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø±ÙØ¹ Ø§Ù„Ø®Ù„ÙÙŠ Ù„Ù„ÙƒØªØ§Ø¨ {book_id}: {e}")
            
        finally:
            # Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø­Ù„ÙŠ Ø¯Ø§Ø¦Ù…Ø§Ù‹ Ù„ØªÙˆÙÙŠØ± Ù…Ø³Ø§Ø­Ø© Ø§Ù„Ø³ÙŠØ±ÙØ±
            if os.path.exists(file_path): 
                os.remove(file_path)

    @staticmethod
    async def upload_cover(image_file):
        """Ø±ÙØ¹ ØµÙˆØ±Ø© ØºÙ„Ø§Ù ÙŠØ¯ÙˆÙŠØ©"""
        content = await image_file.read()
        res = cloudinary.uploader.upload(content, folder="hottiyya_library/covers")
        return res.get("secure_url")

    @staticmethod
    async def add_book(title, author, category, file_url, cover_url, uploader_id, file_size):
        """Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„Ø£ÙˆÙ„ÙŠ Ù„Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        with get_db_context() as conn:
            with conn.cursor() as cur:
                cur.execute("""
                    INSERT INTO library (title, author, category, file_url, cover_url, uploader_id, file_size)
                    VALUES (%s, %s, %s, %s, %s, %s, %s) RETURNING id
                """, (title, author, category, file_url, cover_url, uploader_id, file_size))
                book_id = cur.fetchone()[0]
                conn.commit()
                return book_id

    @staticmethod
    def delete_book(book_id):
        """Ø­Ø°Ù Ø§Ù„ÙƒØªØ§Ø¨ Ù†Ù‡Ø§Ø¦ÙŠØ§Ù‹ Ù…Ù† Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø© ÙˆØ§Ù„Ø³Ø­Ø§Ø¨ (Cloudinary & Drive)"""
        with get_db_context() as conn:
            with conn.cursor(cursor_factory=RealDictCursor) as cur:
                cur.execute("SELECT title, file_url, cover_url FROM library WHERE id = %s", (book_id,))
                book = cur.fetchone()
                if not book: return None

                # 1. Ø­Ø°Ù Ø§Ù„Ø³Ø¬Ù„ Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£ÙˆÙ„Ø§Ù‹
                cur.execute("DELETE FROM library WHERE id = %s", (book_id,))
                conn.commit()

                # 2. Ø­Ø°Ù Ù…Ù„Ù Ø§Ù„ÙƒØªØ§Ø¨ (PDF)
                if book.get('file_url') and book['file_url'] != 'pending' and book['file_url'] != 'error':
                    try:
                        if "drive.google.com" in book['file_url']:
                            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù€ ID Ø¨Ø¯Ù‚Ø© Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø·
                            import urllib.parse as urlparse
                            url_data = urlparse.urlparse(book['file_url'])
                            query = urlparse.parse_qs(url_data.query)
                            file_id = query.get('id', [None])[0]
                            
                            if file_id:
                                service = LibraryService.get_drive_service()
                                service.files().delete(fileId=file_id).execute()
                                print(f"âœ… ØªÙ… Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ù…Ù† Google Drive: {file_id}")
                        else:
                            # Ø­Ø°Ù Ù…Ù† Cloudinary: ÙŠØ¬Ø¨ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„ÙƒØ§Ù…Ù„ ÙˆØ§Ù„Ù…Ø¬Ù„Ø¯
                            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù Ø¨Ø¯ÙˆÙ† Ø§Ù„Ø§Ù…ØªØ¯Ø§Ø¯
                            filename = book['file_url'].split('/')[-1].split('.')[0]
                            public_id = f"hottiyya_library/books/{filename}"
                            cloudinary.uploader.destroy(public_id, resource_type="raw")
                            print(f"âœ… ØªÙ… Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ù…Ù† Cloudinary: {public_id}")
                    except Exception as e:
                        print(f"âš ï¸ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø­Ø°Ù Ù…Ù„Ù Ø§Ù„ÙƒØªØ§Ø¨: {e}")

                # 3. Ø­Ø°Ù ØµÙˆØ±Ø© Ø§Ù„ØºÙ„Ø§Ù
                if book.get('cover_url'):
                    try:
                        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù… Ù…Ù„Ù Ø§Ù„ØºÙ„Ø§Ù
                        cover_name = book['cover_url'].split('/')[-1].split('.')[0]
                        cover_public_id = f"hottiyya_library/covers/{cover_name}"
                        cloudinary.uploader.destroy(cover_public_id)
                        print(f"âœ… ØªÙ… Ø­Ø°Ù Ø§Ù„ØºÙ„Ø§Ù Ù…Ù† Cloudinary: {cover_public_id}")
                    except Exception as e:
                        print(f"âš ï¸ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø­Ø°Ù Ø§Ù„ØºÙ„Ø§Ù: {e}")
                
                return book

    @staticmethod
    def get_books_paginated(category="Ø§Ù„ÙƒÙ„", page=1, per_page=12, search_query=None):
        offset = (page - 1) * per_page
        with get_db_context() as conn:
            with conn.cursor(cursor_factory=RealDictCursor) as cur:
                base_query = "SELECT * FROM library WHERE 1=1"
                count_query = "SELECT COUNT(*) FROM library WHERE 1=1"
                params = []
                if category and category != "Ø§Ù„ÙƒÙ„":
                    base_query += " AND category = %s"; count_query += " AND category = %s"
                    params.append(category)
                if search_query:
                    search_pattern = f"%{search_query}%"
                    base_query += " AND (title ILIKE %s OR author ILIKE %s)"
                    count_query += " AND (title ILIKE %s OR author ILIKE %s)"
                    params.extend([search_pattern, search_pattern])
                cur.execute(count_query, params)
                total_count = cur.fetchone()['count']
                cur.execute(base_query + " ORDER BY created_at DESC LIMIT %s OFFSET %s", params + [per_page, offset])
                return cur.fetchall(), (total_count + per_page - 1) // per_page